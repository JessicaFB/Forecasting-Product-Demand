{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Intro\" data-toc-modified-id=\"Intro-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Intro</a></span></li><li><span><a href=\"#Import-Packages-&amp;-Data\" data-toc-modified-id=\"Import-Packages-&amp;-Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Import Packages &amp; Data</a></span></li><li><span><a href=\"#Clean-&amp;-Explore-Data\" data-toc-modified-id=\"Clean-&amp;-Explore-Data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Clean &amp; Explore Data</a></span></li><li><span><a href=\"#EDA-&amp;-More-Cleaning\" data-toc-modified-id=\"EDA-&amp;-More-Cleaning-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>EDA &amp; More Cleaning</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Warehouses\" data-toc-modified-id=\"Warehouses-4.0.1\"><span class=\"toc-item-num\">4.0.1&nbsp;&nbsp;</span>Warehouses</a></span><ul class=\"toc-item\"><li><span><a href=\"#Product/Order-Demand\" data-toc-modified-id=\"Product/Order-Demand-4.0.1.1\"><span class=\"toc-item-num\">4.0.1.1&nbsp;&nbsp;</span>Product/Order Demand</a></span></li></ul></li><li><span><a href=\"#Products\" data-toc-modified-id=\"Products-4.0.2\"><span class=\"toc-item-num\">4.0.2&nbsp;&nbsp;</span>Products</a></span><ul class=\"toc-item\"><li><span><a href=\"#Product-Count\" data-toc-modified-id=\"Product-Count-4.0.2.1\"><span class=\"toc-item-num\">4.0.2.1&nbsp;&nbsp;</span>Product Count</a></span></li><li><span><a href=\"#Product-Demand\" data-toc-modified-id=\"Product-Demand-4.0.2.2\"><span class=\"toc-item-num\">4.0.2.2&nbsp;&nbsp;</span>Product Demand</a></span></li><li><span><a href=\"#Top-100-Products\" data-toc-modified-id=\"Top-100-Products-4.0.2.3\"><span class=\"toc-item-num\">4.0.2.3&nbsp;&nbsp;</span>Top 100 Products</a></span></li><li><span><a href=\"#Top-50-Products\" data-toc-modified-id=\"Top-50-Products-4.0.2.4\"><span class=\"toc-item-num\">4.0.2.4&nbsp;&nbsp;</span>Top 50 Products</a></span></li><li><span><a href=\"#Discussion\" data-toc-modified-id=\"Discussion-4.0.2.5\"><span class=\"toc-item-num\">4.0.2.5&nbsp;&nbsp;</span>Discussion</a></span></li><li><span><a href=\"#Low-Demand-Products\" data-toc-modified-id=\"Low-Demand-Products-4.0.2.6\"><span class=\"toc-item-num\">4.0.2.6&nbsp;&nbsp;</span>Low Demand Products</a></span></li><li><span><a href=\"#Top-Product\" data-toc-modified-id=\"Top-Product-4.0.2.7\"><span class=\"toc-item-num\">4.0.2.7&nbsp;&nbsp;</span>Top Product</a></span></li></ul></li><li><span><a href=\"#Product-Category\" data-toc-modified-id=\"Product-Category-4.0.3\"><span class=\"toc-item-num\">4.0.3&nbsp;&nbsp;</span>Product Category</a></span></li></ul></li></ul></li><li><span><a href=\"#Modeling\" data-toc-modified-id=\"Modeling-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Modeling</a></span><ul class=\"toc-item\"><li><span><a href=\"#Build-&amp;-Fit-Baseline-Models\" data-toc-modified-id=\"Build-&amp;-Fit-Baseline-Models-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Build &amp; Fit Baseline Models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Daily\" data-toc-modified-id=\"Daily-5.1.1\"><span class=\"toc-item-num\">5.1.1&nbsp;&nbsp;</span>Daily</a></span></li><li><span><a href=\"#Weekly\" data-toc-modified-id=\"Weekly-5.1.2\"><span class=\"toc-item-num\">5.1.2&nbsp;&nbsp;</span>Weekly</a></span></li><li><span><a href=\"#Monthly\" data-toc-modified-id=\"Monthly-5.1.3\"><span class=\"toc-item-num\">5.1.3&nbsp;&nbsp;</span>Monthly</a></span></li></ul></li><li><span><a href=\"#Performance-Metrics\" data-toc-modified-id=\"Performance-Metrics-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Performance Metrics</a></span><ul class=\"toc-item\"><li><span><a href=\"#Crossvalidation\" data-toc-modified-id=\"Crossvalidation-5.2.1\"><span class=\"toc-item-num\">5.2.1&nbsp;&nbsp;</span>Crossvalidation</a></span></li><li><span><a href=\"#Hyperparameter-Tuning\" data-toc-modified-id=\"Hyperparameter-Tuning-5.2.2\"><span class=\"toc-item-num\">5.2.2&nbsp;&nbsp;</span>Hyperparameter Tuning</a></span></li></ul></li></ul></li><li><span><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Conclusion</a></span><ul class=\"toc-item\"><li><span><a href=\"#Results\" data-toc-modified-id=\"Results-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Results</a></span></li><li><span><a href=\"#Recommendations\" data-toc-modified-id=\"Recommendations-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Recommendations</a></span></li><li><span><a href=\"#Future-Work\" data-toc-modified-id=\"Future-Work-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Future Work</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "import datetime\n",
    "\n",
    "from fbprophet import Prophet\n",
    "from fbprophet.diagnostics import cross_validation, performance_metrics\n",
    "from fbprophet.plot import plot_cross_validation_metric\n",
    "\n",
    "import itertools\n",
    "\n",
    "# Filter warnings\n",
    "\n",
    "import logging\n",
    "logging.getLogger('fbprophet').setLevel(logging.ERROR)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data\n",
    "\n",
    "data = pd.read_csv('Historical_Product_Demand.csv')\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product_Code</th>\n",
       "      <th>Warehouse</th>\n",
       "      <th>Product_Category</th>\n",
       "      <th>Date</th>\n",
       "      <th>Order_Demand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Product_0993</td>\n",
       "      <td>Whse_J</td>\n",
       "      <td>Category_028</td>\n",
       "      <td>2012/7/27</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Product_0979</td>\n",
       "      <td>Whse_J</td>\n",
       "      <td>Category_028</td>\n",
       "      <td>2012/1/19</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Product_0979</td>\n",
       "      <td>Whse_J</td>\n",
       "      <td>Category_028</td>\n",
       "      <td>2012/2/3</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Product_0979</td>\n",
       "      <td>Whse_J</td>\n",
       "      <td>Category_028</td>\n",
       "      <td>2012/2/9</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Product_0979</td>\n",
       "      <td>Whse_J</td>\n",
       "      <td>Category_028</td>\n",
       "      <td>2012/3/2</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Product_Code Warehouse Product_Category       Date  Order_Demand\n",
       "0  Product_0993    Whse_J     Category_028  2012/7/27           100\n",
       "1  Product_0979    Whse_J     Category_028  2012/1/19           500\n",
       "2  Product_0979    Whse_J     Category_028   2012/2/3           500\n",
       "3  Product_0979    Whse_J     Category_028   2012/2/9           500\n",
       "4  Product_0979    Whse_J     Category_028   2012/3/2           500"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview Data\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean & Explore Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're fitting time series models, we're going to want to change the Date column to be in datetime format and set it as the index. We'll explore a bit first before getting to that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 999999 entries, 0 to 999998\n",
      "Data columns (total 5 columns):\n",
      "Product_Code        999999 non-null object\n",
      "Warehouse           999999 non-null object\n",
      "Product_Category    999999 non-null object\n",
      "Date                988760 non-null object\n",
      "Order_Demand        999999 non-null int64\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 38.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the 'Date' column has fewer values than the rest of the columns, which indicates missing data. It doesn't look like much of the data are missing, so if they're indeed null, then we can go ahead and drop those rows.\n",
    "\n",
    "We can also see that basically every category other than 'Order_Demand' are objects. That's totally fine as we will use them to categorize, however our time series will simply be date and demand.\n",
    "\n",
    "Let's take a look at our summary statistics for order demand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order_Demand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>999999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>5071.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>29603.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-999000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>4000000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Order_Demand\n",
       "count      999999.0\n",
       "mean         5071.0\n",
       "std         29603.0\n",
       "min       -999000.0\n",
       "25%            20.0\n",
       "50%           300.0\n",
       "75%          2000.0\n",
       "max       4000000.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary statistics\n",
    "df.describe().round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a minimum of -999000.0, it looks like this may be a null value, so we can search for those nulls as well.\n",
    "\n",
    "Let's go ahead and get those rows with null date values removed, and then change our date column into datetime format and rather than set to index actually, we will set it to Facebook Profit's special 'ds' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product_Code</th>\n",
       "      <th>Warehouse</th>\n",
       "      <th>Product_Category</th>\n",
       "      <th>Date</th>\n",
       "      <th>Order_Demand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>585144</td>\n",
       "      <td>Product_1241</td>\n",
       "      <td>Whse_J</td>\n",
       "      <td>Category_019</td>\n",
       "      <td>2014/3/27</td>\n",
       "      <td>-999000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Product_Code Warehouse Product_Category       Date  Order_Demand\n",
       "585144  Product_1241    Whse_J     Category_019  2014/3/27       -999000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.Order_Demand == -999000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Product_Code        False\n",
       "Warehouse           False\n",
       "Product_Category    False\n",
       "Date                 True\n",
       "Order_Demand        False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product_Code</th>\n",
       "      <th>Warehouse</th>\n",
       "      <th>Product_Category</th>\n",
       "      <th>Date</th>\n",
       "      <th>Order_Demand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>45460</td>\n",
       "      <td>Product_1461</td>\n",
       "      <td>Whse_A</td>\n",
       "      <td>Category_019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>456373</td>\n",
       "      <td>Product_1636</td>\n",
       "      <td>Whse_A</td>\n",
       "      <td>Category_019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>456374</td>\n",
       "      <td>Product_1461</td>\n",
       "      <td>Whse_A</td>\n",
       "      <td>Category_019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>456375</td>\n",
       "      <td>Product_1464</td>\n",
       "      <td>Whse_A</td>\n",
       "      <td>Category_019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>456376</td>\n",
       "      <td>Product_1388</td>\n",
       "      <td>Whse_A</td>\n",
       "      <td>Category_019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995790</td>\n",
       "      <td>Product_1464</td>\n",
       "      <td>Whse_A</td>\n",
       "      <td>Category_019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995791</td>\n",
       "      <td>Product_1541</td>\n",
       "      <td>Whse_A</td>\n",
       "      <td>Category_019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995792</td>\n",
       "      <td>Product_1388</td>\n",
       "      <td>Whse_A</td>\n",
       "      <td>Category_019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995793</td>\n",
       "      <td>Product_1541</td>\n",
       "      <td>Whse_A</td>\n",
       "      <td>Category_019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995794</td>\n",
       "      <td>Product_1509</td>\n",
       "      <td>Whse_A</td>\n",
       "      <td>Category_019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11239 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Product_Code Warehouse Product_Category Date  Order_Demand\n",
       "45460   Product_1461    Whse_A     Category_019  NaN         10000\n",
       "456373  Product_1636    Whse_A     Category_019  NaN           100\n",
       "456374  Product_1461    Whse_A     Category_019  NaN           300\n",
       "456375  Product_1464    Whse_A     Category_019  NaN           300\n",
       "456376  Product_1388    Whse_A     Category_019  NaN           200\n",
       "...              ...       ...              ...  ...           ...\n",
       "995790  Product_1464    Whse_A     Category_019  NaN          -900\n",
       "995791  Product_1541    Whse_A     Category_019  NaN          -200\n",
       "995792  Product_1388    Whse_A     Category_019  NaN          -300\n",
       "995793  Product_1541    Whse_A     Category_019  NaN          -300\n",
       "995794  Product_1509    Whse_A     Category_019  NaN          -200\n",
       "\n",
       "[11239 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.Date.isnull() == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like a lot of rows, and that they're all from Warehouse A. Some of them appear to have negative demand as well. Let's take a closer look. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product_Code</th>\n",
       "      <th>Warehouse</th>\n",
       "      <th>Product_Category</th>\n",
       "      <th>Date</th>\n",
       "      <th>Order_Demand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>34593</td>\n",
       "      <td>Product_0905</td>\n",
       "      <td>Whse_A</td>\n",
       "      <td>Category_023</td>\n",
       "      <td>2012/3/7</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41029</td>\n",
       "      <td>Product_0097</td>\n",
       "      <td>Whse_A</td>\n",
       "      <td>Category_019</td>\n",
       "      <td>2012/1/18</td>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41030</td>\n",
       "      <td>Product_1496</td>\n",
       "      <td>Whse_A</td>\n",
       "      <td>Category_019</td>\n",
       "      <td>2012/3/13</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41031</td>\n",
       "      <td>Product_0097</td>\n",
       "      <td>Whse_A</td>\n",
       "      <td>Category_019</td>\n",
       "      <td>2012/4/16</td>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41032</td>\n",
       "      <td>Product_0097</td>\n",
       "      <td>Whse_A</td>\n",
       "      <td>Category_019</td>\n",
       "      <td>2012/9/24</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995797</td>\n",
       "      <td>Product_1822</td>\n",
       "      <td>Whse_A</td>\n",
       "      <td>Category_018</td>\n",
       "      <td>2016/3/1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995798</td>\n",
       "      <td>Product_1470</td>\n",
       "      <td>Whse_A</td>\n",
       "      <td>Category_019</td>\n",
       "      <td>2016/5/19</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995799</td>\n",
       "      <td>Product_0599</td>\n",
       "      <td>Whse_A</td>\n",
       "      <td>Category_017</td>\n",
       "      <td>2016/9/15</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995800</td>\n",
       "      <td>Product_0599</td>\n",
       "      <td>Whse_A</td>\n",
       "      <td>Category_017</td>\n",
       "      <td>2016/10/26</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995801</td>\n",
       "      <td>Product_0148</td>\n",
       "      <td>Whse_A</td>\n",
       "      <td>Category_023</td>\n",
       "      <td>2016/9/15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153574 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Product_Code Warehouse Product_Category        Date  Order_Demand\n",
       "34593   Product_0905    Whse_A     Category_023    2012/3/7            50\n",
       "41029   Product_0097    Whse_A     Category_019   2012/1/18          6000\n",
       "41030   Product_1496    Whse_A     Category_019   2012/3/13          5000\n",
       "41031   Product_0097    Whse_A     Category_019   2012/4/16          6000\n",
       "41032   Product_0097    Whse_A     Category_019   2012/9/24          3900\n",
       "...              ...       ...              ...         ...           ...\n",
       "995797  Product_1822    Whse_A     Category_018    2016/3/1             2\n",
       "995798  Product_1470    Whse_A     Category_019   2016/5/19           100\n",
       "995799  Product_0599    Whse_A     Category_017   2016/9/15            12\n",
       "995800  Product_0599    Whse_A     Category_017  2016/10/26            10\n",
       "995801  Product_0148    Whse_A     Category_023   2016/9/15             1\n",
       "\n",
       "[153574 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subset Warehouse A\n",
    "df[df.Warehouse == 'Whse_A']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like Warehouse A has plenty of data that doesn't have missing dates. Since we will be conducting a time series model, having the date is essential. We will remove these.\n",
    "\n",
    "Let's see how much of the data we will be removing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12%\n"
     ]
    }
   ],
   "source": [
    "# Calculate percentage of data that is null \n",
    "percent_null = (len(df[df.Date.isnull() == True])/len(df))*100\n",
    "print(\"{:.2f}\".format(percent_null) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, just 1.2%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Warehouse.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that Warehouse A is the second largest warehouse. There is a decent amount of variance among the warehouses, so it doesn't seem to be much of an issue to remove the rows.\n",
    "\n",
    "Let's drop the null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaN values (which were only in Date column)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get index of row with large negative order demand \n",
    "df[df.Order_Demand == -999000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop row \n",
    "df = df.drop(index=585144)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll set the Date column to datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now our Date column is set to datetime format so we can subset our data as needed and create time series from it. Now, to the visual exploration (EDA)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA & More Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at product demand for the entire time series. Note: I zoomed in on the x-axis as 2011 data was significantly lower. We'll take a closer look at 2011 following this plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot demand data for entire dataset\n",
    "\n",
    "# Sort by date first for plotting\n",
    "df = df.sort_values('Date')\n",
    "\n",
    "# Set x & y\n",
    "x = df.Date\n",
    "y = df.Order_Demand\n",
    "\n",
    "# Formatting for plots\n",
    "font = {'family' : 'sans',\n",
    "        'weight' : 'regular',\n",
    "        'size'   : 22}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(x, y)\n",
    "\n",
    "# Title & axis labels\n",
    "plt.title('Order Demand')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Order Demand')\n",
    "\n",
    "# Set x-axis limits (low demand data for 2011 - may be able to remove this year)\n",
    "plt.xlim([datetime.date(2012, 1, 1), datetime.date(2017, 1, 1)]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a really big spike mid 2012. I'm curious why. Perhaps there was a promotion or a new product launch or something similar. The demand seems pretty consistent through out the years with a slight drop in Q3 of 2014. \n",
    "\n",
    "Let's get a closer look at 2011 (not pictured here as I intentionally zoomed in on the axis for a better visual of the data). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a time series\n",
    "\n",
    "# Set index to datetime column \n",
    "ts_df = df.set_index('Date')\n",
    "\n",
    "# Select extra columns to drop (everything except 'Order_Demand')\n",
    "to_drop = ['Product_Code','Warehouse','Product_Category']\n",
    "# Drop columns\n",
    "ts = ts_df.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby year\n",
    "ts_yr = ts.groupby(by=ts.index.year).sum()\n",
    "ts_yr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that  2011 and 2017 are significantly lower. Let's find out why. First, we'll make a visual. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot total product demand vs. year\n",
    "\n",
    "# Set figure size\n",
    "plt.figure(figsize=(16,8))\n",
    "# Plot\n",
    "plt.plot(ts_yr.index, ts_yr.Order_Demand)\n",
    "# Title, x & y axis labels\n",
    "plt.title('Sum Total Product Demand Per Year')\n",
    "plt.ylabel('No. Products Ordered')\n",
    "plt.xlabel('Year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We again can see that demand was significantly lower in 2011 and 2017. I imagine these are either incomplete years or that 2011 was just the beginning, so it took time to gain momentum or perhaps not all of the warehouses were open yet. \n",
    "\n",
    "Let's take a closer look to be sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index time series by year 2011\n",
    "ts['2011']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that for 2011 we do have all dates/the entire year present. This may indicate the beginning/when the warehouse(s) were brand new or just starting out. Now let's take a look at 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index time series by year 2017\n",
    "ts['2017']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that for this year the data only go through to January 9th, so 2017 is an incomplete year. \n",
    "\n",
    "We can see that for those years with data for every day, which are years 2012-2016, the order demand is pretty consistent, with 2012 and 2016 being only slightly lower, and 2017 representing only 9 days of the year. \n",
    "\n",
    "So let's go ahead and drop 2011 from our dataset as well as 2017 as it only has data for the first 9 days and is incomplete in terms of weeks or months (which we will be modeling in addition to days)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice 2012 - 2016\n",
    "ts_df = ts_df['2012':'2016']\n",
    "# Preview\n",
    "display(ts_df.head())\n",
    "display(ts_df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks great! Now we can get to building our baseline model and predicting overall demand. This should be pretty easy to do as we can already see there seems to be an overall consistent amount of demand year over year with all warehouses combined.\n",
    "\n",
    "As we move further along we can group by warehouse, and depending how many products there are, we can group by product as well. We already know which warehouses are most productive, as we saw early on when we were cleaning and exploring our data.\n",
    "\n",
    "Let's go ahead and take a look again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warehouses\n",
    "\n",
    "#### Product/Order Demand\n",
    "\n",
    "Let's take a closer look at order demand by warehouse and see if we notice any trends.\n",
    "\n",
    "A quick explanation here: the variable 'Order_Demand' represents the quantity of a specific product that was ordered from any of the four warehouses.\n",
    "\n",
    "It seems that each order is represented individually in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by warehouse and sum order demand\n",
    "wh_demand = ts_df.groupby(by=['Warehouse']).sum().round().sort_values(by=['Order_Demand'], ascending=False)\n",
    "wh_demand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the total percentage of order demand each warehouse represents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate Percentages ###\n",
    "\n",
    "# Warehouses\n",
    "whs = ['Whse_J','Whse_S','Whse_C','Whse_A']\n",
    "# Calc total demand\n",
    "tot_demand = wh_demand.Order_Demand.sum()\n",
    "print(\"Percent of Total Order Demand: \\n\")\n",
    "# Calc percentages\n",
    "for wh in whs:\n",
    "    demand = wh_demand[wh_demand.index == wh].Order_Demand.values[0]\n",
    "    percent_demand = (demand/tot_demand)*100\n",
    "    print(wh + \": {:.2f}\".format(percent_demand) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that Warehouse J has the most demand by a significant amount (more than 3x the following warehouse). This could be the largest warehouse. While Warehouse A represents the smallest amount at less than 3% of total order demand (sum of all units ordered). \n",
    "\n",
    "Let's take a closer look at the summary statistics by warehouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics by warehouse \n",
    "ts_df.groupby(by=['Warehouse']).describe().round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warehouse J has the most orders. Warehouse J also has the highest product demand. Warehouse A interestingly has the second highest orders, however it has the lowest product demand, making up just 2.8% of all units ordered.\n",
    "\n",
    "This is interesting. It would mean perhaps that Warehouse A fulfills a high volume of small orders.\n",
    "\n",
    "Let's visualize these here. We had to use log order demand as the data are spread over a very large range, which causes a lot of outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set figure size\n",
    "plt.figure(figsize=(16,8))\n",
    "# Box plot\n",
    "sns.boxplot(ts_df['Warehouse'], np.log1p(ts_df['Order_Demand']))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we could see in the summary statistics and can also see in our plot here, Warehouses C and S actually have the highest average demand (product count) per order.\n",
    "\n",
    "This is interesting as Warehouse J has the highest total product demand. Warehouse A has the lowest total product demand, however it has the highest number of orders. Additionally as just discussed, Warehouses C and S have the highest average product demand per order.\n",
    "\n",
    "I would be curious to know how big these warehouses are, who they service (who their customers are) and what types of products they carry as well as what metropolitan or otherwise areas they are located in. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Product Count\n",
    "\n",
    "Let's see how many products there are in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are {len(ts_df.Product_Code.unique())} products\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now take a look at the demand.\n",
    "\n",
    "#### Product Demand\n",
    "\n",
    "We're going to sum lifetime product demand by product code and then preview it before visualizing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by product code\n",
    "prod_sum_demand = ts_df.groupby(by=[\"Product_Code\"]).sum()\n",
    "# Sort descending \n",
    "prod_sum_demand = prod_sum_demand.sort_values(by='Order_Demand', ascending=False)\n",
    "# Take a look at the top 20\n",
    "print(\"Top 20 Products:\")\n",
    "display(prod_sum_demand[0:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top products appear to start out pretty high, possibly exponential and then taper out to a slower more linear decrease. \n",
    "\n",
    "Let's go ahead and plot the top 100 products so we can observe the trend visually. \n",
    "\n",
    "#### Top 100 Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x-labels\n",
    "labels = prod_sum_demand.index[0:100]\n",
    "# x-values\n",
    "products = list(range(0,len(labels)))\n",
    "# y-values\n",
    "order_demand = prod_sum_demand.Order_Demand[0:100]\n",
    "\n",
    "# Plot \n",
    "# Set figure\n",
    "plt.figure(figsize=(20,8))\n",
    "# Prevent extra whitespace \n",
    "plt.margins(0.01)\n",
    "# Plot\n",
    "plt.bar(products, order_demand, align='center')\n",
    "# Add labels & rotate 90 degrees\n",
    "plt.xticks(products, labels, rotation = 90, fontsize=10)\n",
    "plt.title('Top 100 Products')\n",
    "plt.ylabel('Lifetime Order Demand')\n",
    "plt.xlabel('Product')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how much the demand for products tapers off. Considering this plot shows lifetime demand as well as only the top 100 out of over 2000, there may be many products with demand lower than what would justify stocking or keeping the product on the floor. \n",
    "\n",
    "Let's take a closer look at that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print 10 lowest demand products\n",
    "prod_sum_demand.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The manufacturer could most likely save costs by freeing up floor space with the elimination of lower demand products. This would make space for more in-demand products and perhaps new products. Or perhaps even downsizing of the facility and staff to only optimize for top producing products.\n",
    "\n",
    "While this isn't the main focus of this study, I will include it as a recommendation in the future work section. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 50 Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x-labels\n",
    "labels = prod_sum_demand.index[0:50]\n",
    "# x-values\n",
    "products = list(range(0,len(labels)))\n",
    "# y-values\n",
    "order_demand = prod_sum_demand.Order_Demand[0:50]\n",
    "\n",
    "# Plot \n",
    "# Set figure\n",
    "plt.figure(figsize=(20,8))\n",
    "# Prevent extra whitespace \n",
    "plt.margins(0.01)\n",
    "# Plot\n",
    "plt.bar(products, order_demand, align='center')\n",
    "# Add labels & rotate 90 degrees\n",
    "plt.xticks(products, labels, rotation = 90, fontsize=16)\n",
    "plt.title('Top 50 Products')\n",
    "plt.ylabel('Lifetime Order Demand')\n",
    "plt.xlabel('Product')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion\n",
    "\n",
    "**Low Demand Inventory**\n",
    "\n",
    "We could see in this section visually that a small percentage of available products make up a very large proportion of orders. If we had more detailed information such as profits from each product, we could do a more detailed analysis here to make suggestions on which products to cut from which warehouses.\n",
    "\n",
    "In an even more detailed analysis it would be good to know footprint of the warehouse as well as number of employees and cost of employees so we could see where things could be culled down and streamlined. How much money can be saved and profits increased. \n",
    "\n",
    "If warehouses were to focus on fewer products which make up the greatest amount of orders/profit, could they then hold more stock of the most popular product and increase demand in other ways, such as advertising and saving money on larger purchase orders/more stock/inventory held? \n",
    "\n",
    "As this analysis is focused on predicting demand, we will focus on that for now, but will mention the above in future work.\n",
    "\n",
    "**Top Demand Inventory**\n",
    "\n",
    "For now let's focus on first modeling and predicting demand for the top most ordered product, and then the model or model-building process can be applied to other products.\n",
    "\n",
    "Since a warehouse is most likely to run out of the most in-demand product and it is imagined that this would also be one of the most highly profitable products, it makes sense that we would focus on the most ordered product(s) first as these would be the most high-impact products."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Low Demand Products\n",
    "\n",
    "Let's take a closer look at some of the individual lower-demand products to gain insights into the products, categories, warehouses and anything else we may gather."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_prods = ['Product_1698','Product_1703','Product_0465']\n",
    "for prod in bottom_prods:\n",
    "    print(f\"{prod}:\")\n",
    "    display(ts_df[ts_df.Product_Code == prod])\n",
    "    print(f\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see some of these have pretty sparse orders. For example the first product with one order being in 2012 and the next being in 2016 with only one product per order each.\n",
    "\n",
    "So far they're all from Warehouse A, which is the second highest producing warehouse, so it wouldn't make sense for them to carry these products that have very little demand, yet take up valuable space.\n",
    "\n",
    "It would only make sense if they were high paying custom orders or something related. \n",
    "\n",
    "Let's take a look at the top product and move forward in our modeling as previously discussed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_prod = ts_df[ts_df.Product_Code == 'Product_1359']\n",
    "top_prod = top_prod.sort_values(by=['Date'])\n",
    "top_prod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_prod_demand = top_prod.groupby(by=['Warehouse']).sum().round().sort_values(by=['Order_Demand'], ascending=False)\n",
    "top_prod_demand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top product is only at Warehouse J. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_df[ts_df.Order_Demand <= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whse_j_prod_demand = ts_df[ts_df.Warehouse == 'Whse_J'].groupby(by=[\"Product_Code\"]).sum().sort_values(by=['Order_Demand'], ascending=False)\n",
    "whse_j_prod_demand.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whse_j_prod_demand[0:100].sum()/whse_j_prod_demand.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whse_j_prod_demand[0:100].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whse_j_prod_demand.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calc total demand\n",
    "tot_demand = whse_j_prod_demand.Order_Demand.sum()\n",
    "print(\"Percent of Total Order Demand: \\n\")\n",
    "\n",
    "# Calc percent\n",
    "demand = whse_j_prod_demand[whse_j_prod_demand.index == 'Product_1359'].Order_Demand.values[0]\n",
    "percent_demand = (demand/tot_demand)*100\n",
    "print(\"Product_1359: {:.2f}\".format(percent_demand) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by product code\n",
    "prod_sum_demand = whse_j_prod_demand.groupby(by=[\"Product_Code\"]).sum()\n",
    "# Sort descending \n",
    "prod_sum_demand = prod_sum_demand.sort_values(by='Order_Demand', ascending=False)\n",
    "# Take a look at the top 20\n",
    "print(\"Top 20 Products:\")\n",
    "display(prod_sum_demand[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of products at warehouse J\n",
    "tot_prods_whse_j = len(prod_sum_demand)\n",
    "print(f\"N Products at Whse J: {tot_prods_whse_j}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x-labels\n",
    "labels = prod_sum_demand.index[0:100]\n",
    "# x-values\n",
    "products = list(range(0,len(labels)))\n",
    "# y-values\n",
    "order_demand = prod_sum_demand.Order_Demand[0:100]\n",
    "\n",
    "# Plot \n",
    "# Set figure\n",
    "plt.figure(figsize=(20,8))\n",
    "# Prevent extra whitespace \n",
    "plt.margins(0.01)\n",
    "# Plot\n",
    "plt.bar(products, order_demand, align='center')\n",
    "# Add labels & rotate 90 degrees\n",
    "plt.xticks(products, labels, rotation = 90, fontsize=10)\n",
    "plt.title('Top 100 Products at Warehouse J')\n",
    "plt.ylabel('Lifetime Order Demand')\n",
    "plt.xlabel('Product')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x-labels\n",
    "labels = prod_sum_demand.index[0:50]\n",
    "# x-values\n",
    "products = list(range(0,len(labels)))\n",
    "# y-values\n",
    "order_demand = prod_sum_demand.Order_Demand[0:50]\n",
    "\n",
    "# Plot \n",
    "# Set figure\n",
    "plt.figure(figsize=(20,8))\n",
    "# Prevent extra whitespace \n",
    "plt.margins(0.01)\n",
    "# Plot\n",
    "plt.bar(products, order_demand, align='center')\n",
    "# Add labels & rotate 90 degrees\n",
    "plt.xticks(products, labels, rotation = 90, fontsize=16)\n",
    "plt.title('Top 50 Products')\n",
    "plt.ylabel('Lifetime Order Demand')\n",
    "plt.xlabel('Product')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary Statistics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_prod.describe().round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The max orders in a day have been just under 10M units, with the 75th percentile being just over 4M, 50th percentile being just over 3M and mean being a bit under 3M. \n",
    "\n",
    "The min is -400, which would indicate that there were higher returns than orders. This can be a bit misleading as it doesn't show actual demand for the day, which is more important as inventory forecasting has the purpose of meeting demand. Let's see how much of the data is <= 0 for daily demand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate % of data with daily product demand <= 0 \n",
    "print('{:.2f}%'.format(len(top_prod[top_prod.y <=0 ])/len(top_prod)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that 8.71% of the data show <= 0 for daily demand, which isn't that much. We can still get an idea for how much product to have on hand at any given time.\n",
    "\n",
    "Let's take a look at the distribution for this.\n",
    "\n",
    "**Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.distplot(top_prod.y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this distribution is bimodal. Often there are small or no orders in a day. However, we have another distrobution where we can see the mean in between 2M & 3M, which we saw from the summary statistics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product Category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a closer look at the highest demand product category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Group by product category & sum order demand\n",
    "top_cat = ts_df.groupby(by=['Product_Category']).sum()\n",
    "# Sort descending by order demand\n",
    "top_cat = top_cat.sort_values(by=['Order_Demand'], ascending=False)\n",
    "# Preview top 5\n",
    "top_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that Category 19 is the most demanded product. This makes sense as it is the category that our most in-demand product  Let's visualize this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "sns.countplot(x='Product_Category', \n",
    "              data=ts_df,\n",
    "              order = ts_df['Product_Category'].value_counts().index)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Category 19 is by far the most in demand product. We can see it really taper off, especially when the lifetime demand for an entire category over the span of approximately 6 years is less than 100. \n",
    "\n",
    "Intuitively I would recommend nixing these products. However, if they are extremely high profit products, they may be able to be justified, however that is a far stretch with such low demand over around 6 years, assuming the products have been there since the beginning. \n",
    "\n",
    "Another thing to consider is as these are value counts this is essentially all of the days the products were ordered. There could be different amounts of the product ordered each day, which is represented by 'Order Demand'. We'll take a look at that next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lifetime demand of each product category\n",
    "\n",
    "ts_df_cat = ts_df.groupby(by=ts_df.Product_Category).sum()\n",
    "ts_df_cat = ts_df_cat.sort_values(by='Order_Demand', ascending=False)\n",
    "ts_df_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variables and labels \n",
    "\n",
    "# x-labels\n",
    "labels = ts_df_cat.index\n",
    "# x-values\n",
    "products = list(range(0,len(labels)))\n",
    "# y-values\n",
    "order_demand = ts_df_cat.Order_Demand\n",
    "\n",
    "# Plot \n",
    "# Set figure\n",
    "plt.figure(figsize=(20,8))\n",
    "# Plot\n",
    "plt.bar(products, order_demand, align='center')\n",
    "# Add labels & rotate 90 degrees\n",
    "plt.xticks(products, labels, rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set figure size\n",
    "plt.figure(figsize=(16,8))\n",
    "# Box plot\n",
    "sns.boxplot(ts_df['Product_Category'], np.log1p(ts_df['Order_Demand']))\n",
    "plt.xticks(products, labels, rotation = 90)\n",
    "plt.title('log Average Product Demand Per Order Per Category')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot is interesting, because what it shows is that our top producing category (Category 19) actually has fewer demand per order than many other product categories. This would indicate that it is ordered both frequently and perhaps from many different customers. Whatever the products in this category may be it seems they are used by many and frequently. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build & Fit Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Metric\n",
    "\n",
    "**MAPE**\n",
    "\n",
    "In order for our model to calculate MAPE, we will need to remove rows where daily demand is <= 0. The reason we're using MAPE, rather than RMSE or simply MAE, is because RMSE and MAE are proportional to the regular demand of a product, which would vary greatly as we apply our model to different products. To keep our accuracy score relatable and relevant amongst different products that we apply our model to, MAPE, which represents percentage, is the best metric to use. \n",
    "\n",
    "**Negative Demand**\n",
    "\n",
    "Negative demand indicates returns were made that day. However, we don't know if the returns logged that day are immediately available to be shipped out. Therefore they are not useful in knowing how much product to have on hand to meet demand.\n",
    "\n",
    "This is a common issue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_df_day = ts_df.groupby(pd.Grouper(freq='D')).sum()\n",
    "ts_df_day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MOVE THIS TO TOP -- REMOVE FROM DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_zero_demand = len(ts_df[ts_df.Order_Demand <= 0])/len(ts_df)*100\n",
    "print(\"{:.2f}\".format(percent_zero_demand) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_df = ts_df[ts_df.Order_Demand > 0]\n",
    "ts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was the same number we got when looking at our top product. It\n",
    "could be returns of our top product, which is ordered in high volumes that affect the daily sum of all products at all warehouses. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_model(ts_df, freq='D', periods=365):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    ### Group data by Frequency ###\n",
    "    \n",
    "    # Group by frequency\n",
    "    top_prod = ts_df.groupby(pd.Grouper(freq=freq)).sum()\n",
    "\n",
    "    # Preview\n",
    "    print('Time Series Head:')\n",
    "    display(top_prod.head())\n",
    "    print('Time Series Tail:')\n",
    "    display(top_prod.tail())\n",
    "    \n",
    "    ### Convert to fbprophet format ###\n",
    "\n",
    "    # Move datetime index to column\n",
    "    top_prod.reset_index(inplace=True)\n",
    "    # Rename columns for fbprophet format\n",
    "    top_prod = top_prod.rename(columns={'Date':'ds', 'Order_Demand': 'y'})\n",
    "\n",
    "    ### Instantiate & Fit Model ###\n",
    "\n",
    "    # Instantiate model\n",
    "    m = Prophet(interval_width=0.95)\n",
    "    # Fit model\n",
    "    m.fit(top_prod)\n",
    "\n",
    "    ### Forecast & Predict ###\n",
    "\n",
    "    # Forcasting 3 months into the future\n",
    "    future = m.make_future_dataframe(periods=periods, freq=freq)\n",
    "    # Predict\n",
    "    forecast = m.predict(future)\n",
    "\n",
    "    ### Preview Forecast ###\n",
    "\n",
    "    # Head\n",
    "    print('Forecast Head:')\n",
    "    display(forecast[['ds', 'trend','yhat', 'yhat_lower', 'yhat_upper']].head().round())\n",
    "    # Tail\n",
    "    print('Forecast Tail:')\n",
    "    display(forecast[['ds', 'trend','yhat', 'yhat_lower', 'yhat_upper']].tail().round())\n",
    "\n",
    "    ### Calculate RMSE ###\n",
    "\n",
    "    # Residuals\n",
    "    res = top_prod.y - forecast.yhat[:-periods]\n",
    "    # Residual sum of squares\n",
    "    rss = np.sum(np.square(res))\n",
    "    # Mean squared error\n",
    "    mse = rss/len(res)\n",
    "    # Root mean squared error\n",
    "    rmse = np.sqrt(mse)\n",
    "    # Print\n",
    "    print(f\"RMSE: {rmse.round()} \\n\")\n",
    "\n",
    "    ### Plot Time Series & Components ###\n",
    "\n",
    "    # Plot forecast\n",
    "    print('Time Series Forecast:')\n",
    "    figure1 = m.plot(forecast, xlabel = 'Date', ylabel = 'Order Demand',uncertainty=True)\n",
    "    # Add change points\n",
    "    a = add_changepoints_to_plot(figure1.gca(), m, forecast)\n",
    "    plt.show()\n",
    "    # Plot components\n",
    "    print('Time Series Components:')\n",
    "    figure2 = m.plot_components(forecast)\n",
    "    plt.show()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daily \n",
    "\n",
    "Apply function to model daily demand forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_model(ts_df, freq='D', periods=365)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RMSE: 1148398.0**\n",
    "\n",
    "**Trend**\n",
    "\n",
    "We can see there is a series of changepoints surrounding the beginning of 2015. This relates to the overall trend we can see in the decomposition trend plot. \n",
    "\n",
    "The trend increases linearly peaking in 2015 and then linearly decreases.\n",
    "\n",
    "This could have been the introduction of a new product that peaked before trending downward in its product lifecycle. This could have been a change in industry trends. This could have been due to competitor product(s). This could have been the result of a marketing or promotional campaign. There are many possibilities.\n",
    "\n",
    "We don't have much information on this dataset other than it coming from a manufacturer with four worldwide warehouses. \n",
    "\n",
    "**Weekly**\n",
    "\n",
    "It appears there is a peak in demand/orders on Tuesday, followed closely by Monday, with Wednesday being the slowest day and negative demand (which could indicate returns) on the weekends. This seems to follow a Monday - Friday business day schedule. \n",
    "\n",
    "**Yearly**\n",
    "\n",
    "There appear to be peaks in December and February, before and after the holidays and new year, with the lowest amount of demand in January. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekly \n",
    "\n",
    "Apply function to model weekly demand forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_model(ts_df, freq='W', periods=52)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RMSE: 3407993.0**\n",
    "\n",
    "We can see the same trends here as the daily projections, however the RMSE for weekly is much higher (almost 300%) than the daily. Therefore daily demand is a more accurate prediction metric for this model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly \n",
    "\n",
    "Apply function to model monthly demand forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ts_model(ts_df, freq='M', periods=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RMSE: 4998711.0**\n",
    "\n",
    "We can see the 2015 changepoint most clearly here. One thing to note is that by looking on a monthly basis rather than daily or weekly, the yearly trends have shifted.\n",
    "\n",
    "We can also see the RMSE is the highest for this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Selection**\n",
    "\n",
    "With the lowest RMSE by a significant amount, we will go with daily forecasting for our time series model, and do our best to tune it below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we have looked at RMSE, we will also crossvalidate and perform a gridsearch to find optimal values for our hyperparameters. We will plot RMSE and take a look at MAE as well (mean absolute error). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Cross validation ##\n",
    "top_prod = ts_df.groupby(pd.Grouper(freq='D')).sum()\n",
    "# Move datetime index to column\n",
    "top_prod.reset_index(inplace=True)\n",
    "# Rename columns for fbprophet format\n",
    "top_prod = top_prod.rename(columns={'Date':'ds', 'Order_Demand': 'y'})\n",
    "\n",
    "### Instantiate & Fit Model ###\n",
    "\n",
    "# Instantiate model\n",
    "m = Prophet(interval_width=0.95)\n",
    "# Fit model\n",
    "m.fit(top_prod)\n",
    "\n",
    "\n",
    "top_prod_d_cv = cross_validation(m, initial='365.25 days', period='365.25 days', horizon = '365.25 days')\n",
    "\n",
    "# Performance metrics\n",
    "top_prod_p = performance_metrics(top_prod_d_cv)\n",
    "\n",
    "# RMSE\n",
    "min_rmse = top_prod_p.sort_values(by=['rmse']).head(1)['rmse'].round().values[0]\n",
    "max_rmse = top_prod_p.sort_values(by=['rmse'], ascending=False).head(1)['rmse'].round().values[0]\n",
    "\n",
    "# Print\n",
    "print(f'Min RMSE: {min_rmse}')\n",
    "print(f'Max RMSE: {max_rmse}')\n",
    "\n",
    "### Plot Metrics ###\n",
    "\n",
    "fig = plot_cross_validation_metric(top_prod_d_cv, metric='rmse')#, rolling_window=.2)\n",
    "plt.title('RMSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that the prediction error (RMSE) for our model ranges from 961842.0 - 1463890.0 depending on the horizon or days into the future that we're predicting.\n",
    "\n",
    "Let's take a closer look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction metrics for min RMSE\n",
    "top_prod_p.sort_values(by=['rmse']).head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the optimal prediction horizon is 324 days. Therefore we can say that our model most accurately predicts 324 days into the future. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {  \n",
    "    'changepoint_prior_scale': [0.001, 0.01, 0.1, 0.5],\n",
    "    'seasonality_prior_scale': [3, 5, 10, 15],\n",
    "}\n",
    "\n",
    "# Generate all combinations of parameters\n",
    "all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
    "rmses = []  # Store the RMSEs for each params here\n",
    "\n",
    "# Use cross validation to evaluate all parameters\n",
    "for params in all_params:\n",
    "    m = Prophet(**params).fit(top_prod)  # Fit model with given params\n",
    "    df_cv = cross_validation(m, horizon='365.25 days')\n",
    "    df_p = performance_metrics(df_cv, rolling_window=1)\n",
    "    rmses.append(df_p['rmse'].values[0])\n",
    "\n",
    "# Find the best parameters\n",
    "tuning_results = pd.DataFrame(all_params)\n",
    "tuning_results['rmse'] = rmses\n",
    "print(tuning_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = all_params[np.argmin(rmses)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of these appear to improve the model as we can see with the relatively RMSE values. We can however test them out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model with chosen hyperparameters\n",
    "m = Prophet(interval_width = 0.95,\n",
    "            yearly_seasonality = True,\n",
    "            weekly_seasonality = True,\n",
    "            daily_seasonality = False,\n",
    "            changepoint_prior_scale = 0.5,\n",
    "            seasonality_prior_scale=10\n",
    "            )\n",
    "\n",
    "# Add holidays\n",
    "m.add_country_holidays(country_name='US')\n",
    "# Fit model\n",
    "m.fit(top_prod)\n",
    "\n",
    "# Forcast 324 days into the future\n",
    "future = m.make_future_dataframe(periods=324, freq='D')\n",
    "forecast = m.predict(future)\n",
    "\n",
    "display(forecast[['ds', 'trend','yhat', 'yhat_lower', 'yhat_upper']].tail().round())\n",
    "\n",
    "figure1 = m.plot(forecast, xlabel = 'Date', ylabel = 'Order Demand',uncertainty=True)\n",
    "a = add_changepoints_to_plot(figure1.gca(), m, forecast)\n",
    "figure2 = m.plot_components(forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can really see in comparison to our trend plot how the changepoints have really captured the trend. We can see this did increase the undertainty, which could indicate that our model is overfitting due to our tuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RMSE\n",
    "res = top_prod.y - forecast.yhat[:-324]\n",
    "rss = np.sum(np.square(res))\n",
    "mse = rss/len(res)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"RMSE: {rmse.round()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were able to improve the model slightly, by approximately 20,000 units per day more accurate, however we may be overfitting the model here. \n",
    "\n",
    "I'm curious now to see what the summary statistics are for daily demand of this product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_prod_d_cv = cross_validation(m, initial='365.25 days', period='365.25 days', horizon = '365.25 days')\n",
    "display(top_prod_d_cv.head())\n",
    "display(top_prod_d_cv.tail())\n",
    "\n",
    "top_prod_p = performance_metrics(top_prod_d_cv)\n",
    "print('Min MAE:')\n",
    "display(top_prod_p.sort_values(by=['mae']).head())\n",
    "print('Min RMSE:')\n",
    "display(top_prod_p.sort_values(by=['rmse']).head())\n",
    "\n",
    "fig = plot_cross_validation_metric(top_prod_d_cv, metric='mae')\n",
    "plt.title('Cross Validation : MAE')\n",
    "plt.show()\n",
    "fig = plot_cross_validation_metric(top_prod_w_cv, metric='rmse')\n",
    "plt.title('Cross Validation : RMSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "204.716px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
